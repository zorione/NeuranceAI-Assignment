{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.7.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Introduction\n- This version uses TF-IDF Vectorizer, which considers only the `5000` max_features ordered by term frequency across the corpus.\n- For the training, I have used Linear Regression.","metadata":{}},{"cell_type":"markdown","source":"# 1. Importing Packages","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19"}},{"cell_type":"code","source":"### Basic Packages\nimport os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Ref: https://docs.python.org/3/library/string.html\nimport re,string,unicodedata\nfrom bs4 import BeautifulSoup\n\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error as MSE\nfrom sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n\n### NLTK Imports\nimport nltk\nfrom nltk import pos_tag, word_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.corpus import sentiwordnet as swn, wordnet\nfrom nltk.corpus.reader.wordnet import WordNetError\nfrom nltk.stem import LancasterStemmer,WordNetLemmatizer\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.tokenize import word_tokenize,sent_tokenize\nfrom nltk.tokenize.toktok import ToktokTokenizer","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:16.992450Z","iopub.execute_input":"2022-08-21T11:52:16.992971Z","iopub.status.idle":"2022-08-21T11:52:19.345978Z","shell.execute_reply.started":"2022-08-21T11:52:16.992873Z","shell.execute_reply":"2022-08-21T11:52:19.344558Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"np.random.seed(0)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:19.349497Z","iopub.execute_input":"2022-08-21T11:52:19.350059Z","iopub.status.idle":"2022-08-21T11:52:19.356294Z","shell.execute_reply.started":"2022-08-21T11:52:19.350004Z","shell.execute_reply":"2022-08-21T11:52:19.355318Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Ref: https://www.nltk.org/data.html\n# Ref: https://www.nltk.org/_modules/nltk/corpus.html\nnltk.download('omw-1.4')","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:19.357979Z","iopub.execute_input":"2022-08-21T11:52:19.358649Z","iopub.status.idle":"2022-08-21T11:52:19.669464Z","shell.execute_reply.started":"2022-08-21T11:52:19.358612Z","shell.execute_reply":"2022-08-21T11:52:19.668252Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"markdown","source":"# 2. Exploration","metadata":{}},{"cell_type":"code","source":"df_train = pd.read_csv(\"../input/neuranceai/train.csv\")\ndf_test  = pd.read_csv(\"../input/neuranceai/test.csv\")","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:19.673071Z","iopub.execute_input":"2022-08-21T11:52:19.673562Z","iopub.status.idle":"2022-08-21T11:52:20.344875Z","shell.execute_reply.started":"2022-08-21T11:52:19.673513Z","shell.execute_reply":"2022-08-21T11:52:20.343748Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"print(df_train.info())\ndf_train.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-21T11:52:20.346558Z","iopub.execute_input":"2022-08-21T11:52:20.347045Z","iopub.status.idle":"2022-08-21T11:52:20.405892Z","shell.execute_reply.started":"2022-08-21T11:52:20.346998Z","shell.execute_reply":"2022-08-21T11:52:20.404693Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"print(df_test.info())\ndf_test.head()","metadata":{"scrolled":true,"execution":{"iopub.status.busy":"2022-08-21T11:52:20.407949Z","iopub.execute_input":"2022-08-21T11:52:20.408416Z","iopub.status.idle":"2022-08-21T11:52:20.437767Z","shell.execute_reply.started":"2022-08-21T11:52:20.408371Z","shell.execute_reply":"2022-08-21T11:52:20.436442Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"print(\"TRAINING DATASET\")\nprint(\"#Unique Drug Names: \", len(np.unique(df_train['name_of_drug'])))\nprint(\"#Unique Use Cases: \", len(np.unique(df_train['use_case_for_drug'])))\n\nprint(\"\\nTEST DATASET\")\nprint(\"#Unique Drug Names: \", len(np.unique(df_test['name_of_drug'])))\nprint(\"#Unique Use Cases: \", len(np.unique(df_test['use_case_for_drug'])))","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:20.439336Z","iopub.execute_input":"2022-08-21T11:52:20.440018Z","iopub.status.idle":"2022-08-21T11:52:20.505619Z","shell.execute_reply.started":"2022-08-21T11:52:20.439972Z","shell.execute_reply":"2022-08-21T11:52:20.504509Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"markdown","source":"# 3. Pre-Processing","metadata":{}},{"cell_type":"code","source":"# Making a list of all the stopwords\nstop_words = set(stopwords.words('english'))\npunctuation = list(string.punctuation)\nstop_words.update(punctuation)\n\n# A function to determine the tag for every word\n# Ref: https://www.nltk.org/api/nltk.tag.html\ndef get_simple_pos(tag):\n    if tag.startswith('J'):\n        return wordnet.ADJ\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('N'):\n        return wordnet.NOUN\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN\n    \n# Creating a function to lemmatize the review text\n# Ref: https://www.nltk.org/_modules/nltk/stem/wordnet.html\nlemmatizer = WordNetLemmatizer()\ndef lemmatize_words(review_by_patient):\n    final_text = []\n    for i in review_by_patient.split():\n        if i.strip().lower() not in stop_words:\n            # Tag of the word, used for lemmatization\n            pos = pos_tag([i.strip()]) \n            word = lemmatizer.lemmatize(i.strip(),get_simple_pos(pos[0][1]))\n            final_text.append(word.lower())\n    return \" \".join(final_text)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:20.507099Z","iopub.execute_input":"2022-08-21T11:52:20.507628Z","iopub.status.idle":"2022-08-21T11:52:20.520930Z","shell.execute_reply.started":"2022-08-21T11:52:20.507593Z","shell.execute_reply":"2022-08-21T11:52:20.519920Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"is_df_train = os.path.isfile(\"../input/neuranceai/new_df_train.csv\")\nis_df_test  = os.path.isfile(\"../input/neuranceai/new_df_test.csv\")\n\nif is_df_train and is_df_test:\n    new_df_train = pd.read_csv(\"../input/neuranceai/new_df_train.csv\")\n    new_df_test = pd.read_csv(\"../input/neuranceai/new_df_test.csv\")\nelse:\n    reviews_train = df_train['review_by_patient']\n    reviews_test = df_test['review_by_patient']\n    print(reviews_train.shape, reviews_test.shape)\n\n    # Performing Lemmatization\n    reviews_train = reviews_train.apply(lemmatize_words)\n    reviews_test = reviews_test.apply(lemmatize_words)\n    print(reviews_train.shape, reviews_test.shape)\n\n    # Creating a new dataset with lemmatized words\n    new_df_train = df_train.drop(['review_by_patient'], axis = 1)\n    new_df_test  = df_test.drop(['review_by_patient'], axis = 1)\n    print(new_df_train.shape, new_df_test.shape)\n\n    new_df_train = pd.concat([new_df_train, reviews_train], axis = 1)\n    new_df_test = pd.concat([new_df_test, reviews_test], axis = 1)\n    print(new_df_train.shape, new_df_test.shape)\n\n    new_df_train.to_csv(\"new_df_train.csv\", index = False)\n    new_df_test.to_csv(\"new_df_test.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:20.522656Z","iopub.execute_input":"2022-08-21T11:52:20.523227Z","iopub.status.idle":"2022-08-21T11:52:21.046761Z","shell.execute_reply.started":"2022-08-21T11:52:20.523161Z","shell.execute_reply":"2022-08-21T11:52:21.045651Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"# Removing the variables from the memory, only works with one variable at a time\n# reset_selective -f <variable>\n\n# To find the variables in the memory\n# who_ls","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:21.052525Z","iopub.execute_input":"2022-08-21T11:52:21.052949Z","iopub.status.idle":"2022-08-21T11:52:21.058309Z","shell.execute_reply.started":"2022-08-21T11:52:21.052911Z","shell.execute_reply":"2022-08-21T11:52:21.056990Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"tf_idf = TfidfVectorizer(max_features = 5000)\nreviews_train = tf_idf.fit_transform(new_df_train['review_by_patient'])\nreviews_test = tf_idf.transform(new_df_test['review_by_patient'])\nprint(reviews_train.shape, reviews_test.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:21.060054Z","iopub.execute_input":"2022-08-21T11:52:21.061308Z","iopub.status.idle":"2022-08-21T11:52:23.128672Z","shell.execute_reply.started":"2022-08-21T11:52:21.061265Z","shell.execute_reply":"2022-08-21T11:52:23.127239Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"# 4. Preparing the Dataset for modelling purposes","metadata":{}},{"cell_type":"code","source":"X_train = new_df_train.drop(['patient_id', 'name_of_drug', 'use_case_for_drug', \n    'drug_approved_by_UIC', 'review_by_patient', 'base_score'], axis = 1)\nY_train = new_df_train['base_score']\nX_test = new_df_test.drop(['patient_id', 'name_of_drug', 'use_case_for_drug', \n    'drug_approved_by_UIC', 'review_by_patient'], axis = 1)\ntest_ids = new_df_test['patient_id']\n\nX_train = pd.concat([X_train, pd.DataFrame(reviews_train.toarray())], axis = 1)\nX_test = pd.concat([X_test, pd.DataFrame(reviews_test.toarray())], axis = 1)\nprint(\"Trainin Set:\", X_train.shape, Y_train.shape)\nprint(\"Test Set:\", X_test.shape, test_ids.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:23.130826Z","iopub.execute_input":"2022-08-21T11:52:23.131338Z","iopub.status.idle":"2022-08-21T11:52:31.356587Z","shell.execute_reply.started":"2022-08-21T11:52:23.131291Z","shell.execute_reply":"2022-08-21T11:52:31.354973Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Dividing the labelled examples into training and validation examples\nx_train, x_val, y_train, y_val = train_test_split(X_train, Y_train, test_size = 0.1)\nprint(x_train.shape, x_val.shape, y_train.shape, y_val.shape)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:31.358163Z","iopub.execute_input":"2022-08-21T11:52:31.358555Z","iopub.status.idle":"2022-08-21T11:52:33.301548Z","shell.execute_reply.started":"2022-08-21T11:52:31.358520Z","shell.execute_reply":"2022-08-21T11:52:33.300230Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"reset_selective -f X_train","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:33.303203Z","iopub.execute_input":"2022-08-21T11:52:33.303615Z","iopub.status.idle":"2022-08-21T11:52:33.314058Z","shell.execute_reply.started":"2022-08-21T11:52:33.303572Z","shell.execute_reply":"2022-08-21T11:52:33.313049Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"reset_selective -f Y_train","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:33.316046Z","iopub.execute_input":"2022-08-21T11:52:33.316422Z","iopub.status.idle":"2022-08-21T11:52:33.330091Z","shell.execute_reply.started":"2022-08-21T11:52:33.316387Z","shell.execute_reply":"2022-08-21T11:52:33.328660Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"markdown","source":"# 5. Training the Model","metadata":{}},{"cell_type":"code","source":"lr = LinearRegression()\nlr.fit(x_train, y_train)\n\npreds_train = lr.predict(x_train)\npreds_val = lr.predict(x_val)\n\nRMSE_train = MSE(y_train, preds_train, squared = False)\nRMSE_val = MSE(y_val, preds_val, squared = False)\n\nprint(\"Root Mean Squared Error for Training Set:\", RMSE_train)\nprint(\"Root Mean Squared Error for Validation Set:\", RMSE_val)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:52:33.332262Z","iopub.execute_input":"2022-08-21T11:52:33.332953Z","iopub.status.idle":"2022-08-21T11:54:29.999601Z","shell.execute_reply.started":"2022-08-21T11:52:33.332905Z","shell.execute_reply":"2022-08-21T11:54:29.997365Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"markdown","source":"# 6. Predicting Results","metadata":{}},{"cell_type":"code","source":"preds_test = lr.predict(X_test)\nprint(test_ids.shape, preds_test.shape)\n\nsam_sub = pd.concat([test_ids, pd.Series(preds_test)], axis = 1)\nsam_sub.to_csv(\"sample_submission.csv\", index = False)","metadata":{"execution":{"iopub.status.busy":"2022-08-21T11:54:30.008802Z","iopub.execute_input":"2022-08-21T11:54:30.010089Z","iopub.status.idle":"2022-08-21T11:54:30.566997Z","shell.execute_reply.started":"2022-08-21T11:54:30.010006Z","shell.execute_reply":"2022-08-21T11:54:30.565354Z"},"trusted":true},"execution_count":17,"outputs":[]}]}